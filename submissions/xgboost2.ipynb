{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "import warnings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('../data/LOANS_TRAIN.csv')\n",
    "test_data = pd.read_csv('../data/LOANS_TEST.csv')\n",
    "\n",
    "id_column = train_data\n",
    "\n",
    "train_data.drop(columns=['id','grade', 'emp_title', 'title'], axis=1, inplace=True)\n",
    "test_data.drop(columns=['id','grade', 'emp_title', 'title'], axis=1, inplace=True)\n",
    "\n",
    "labelencoder = LabelEncoder()\n",
    "# Assigning numerical values and storing in another column\n",
    "train_data['sub_grade'] = labelencoder.fit_transform(train_data['sub_grade'])\n",
    "train_data['home_ownership'] = labelencoder.fit_transform(train_data['home_ownership'])\n",
    "train_data['emp_length'].replace('< 1 year', 0.5, inplace=True)\n",
    "train_data['emp_length'].replace('1 year', 1.0, inplace=True)\n",
    "train_data['emp_length'].replace('2 years', 2.0, inplace=True)\n",
    "train_data['emp_length'].replace('3 years', 3.0, inplace=True)\n",
    "train_data['emp_length'].replace('4 years', 4.0, inplace=True)\n",
    "train_data['emp_length'].replace('5 years', 5.0, inplace=True)\n",
    "train_data['emp_length'].replace('6 years', 6.0, inplace=True)\n",
    "train_data['emp_length'].replace('7 years', 7.0, inplace=True)\n",
    "train_data['emp_length'].replace('8 years', 8.0, inplace=True)\n",
    "train_data['emp_length'].replace('9 years', 9.0, inplace=True)\n",
    "train_data['emp_length'].replace('10 years', 10.0, inplace=True)\n",
    "train_data['emp_length'].replace('10+ years', 15.0, inplace=True)\n",
    "train_data['emp_length'] = train_data['emp_length'].fillna(0)\n",
    "\n",
    "train_data['mort_acc'] = train_data['mort_acc'].fillna(0)\n",
    "# Strip percent(%) from int_rate\n",
    "train_data['int_rate'] = train_data['int_rate'].str.rstrip('%').astype(float)\n",
    "test_data['int_rate'] = test_data['int_rate'].str.rstrip('%').astype(float)\n",
    "\n",
    "#Strip percent(%) from revol_util\n",
    "train_data['revol_util'] = train_data['revol_util'].str.rstrip('%').astype(float)\n",
    "test_data['revol_util'] = test_data['revol_util'].str.rstrip('%').astype(float)\n",
    "\n",
    "X_train = train_data.iloc[:,:-1]\n",
    "y_train = train_data.iloc[:,-1]\n",
    "X_test = test_data.iloc[:,:]\n",
    "\n",
    "X_train_numeric = X_train.select_dtypes(include=np.number)\n",
    "X_test_numeric = X_train.select_dtypes(include=np.number)\n",
    "# y_train_numeric = y_train.select_dtypes(include=np.number)\n",
    "y_train_numeric = y_train.copy(deep=False)\n",
    "y_train_numeric.replace('Fully Paid', 0.0, inplace=True)\n",
    "y_train_numeric.replace('Charged Off', 1.0, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding artificial Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'> <class 'pandas.core.series.Series'> <class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "print(type(X_train_numeric), type(y_train_numeric), type(X_test))\n",
    "\n",
    "# print(\"BEFORE\")\n",
    "# print(X_train_numeric.shape)\n",
    "# print(y_train_numeric.shape)\n",
    "# print('AFTER')\n",
    "# print(X_balanced.shape)\n",
    "# print(Y_balanced.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>term_(months)</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>installment</th>\n",
       "      <th>sub_grade</th>\n",
       "      <th>emp_length</th>\n",
       "      <th>home_ownership</th>\n",
       "      <th>annual_inc</th>\n",
       "      <th>dti</th>\n",
       "      <th>open_acc</th>\n",
       "      <th>pub_rec</th>\n",
       "      <th>revol_bal</th>\n",
       "      <th>revol_util</th>\n",
       "      <th>total_acc</th>\n",
       "      <th>mort_acc</th>\n",
       "      <th>pub_rec_bankruptcies</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5000</td>\n",
       "      <td>36</td>\n",
       "      <td>10.65</td>\n",
       "      <td>162.87</td>\n",
       "      <td>6</td>\n",
       "      <td>15.0</td>\n",
       "      <td>4</td>\n",
       "      <td>24000.0</td>\n",
       "      <td>27.65</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>13648</td>\n",
       "      <td>83.7</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2500</td>\n",
       "      <td>60</td>\n",
       "      <td>15.27</td>\n",
       "      <td>59.83</td>\n",
       "      <td>13</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1687</td>\n",
       "      <td>9.4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2400</td>\n",
       "      <td>36</td>\n",
       "      <td>15.96</td>\n",
       "      <td>84.33</td>\n",
       "      <td>14</td>\n",
       "      <td>15.0</td>\n",
       "      <td>4</td>\n",
       "      <td>12252.0</td>\n",
       "      <td>8.72</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2956</td>\n",
       "      <td>98.5</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10000</td>\n",
       "      <td>36</td>\n",
       "      <td>13.49</td>\n",
       "      <td>339.31</td>\n",
       "      <td>10</td>\n",
       "      <td>15.0</td>\n",
       "      <td>4</td>\n",
       "      <td>49200.0</td>\n",
       "      <td>20.00</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>5598</td>\n",
       "      <td>21.0</td>\n",
       "      <td>37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3000</td>\n",
       "      <td>60</td>\n",
       "      <td>12.69</td>\n",
       "      <td>67.79</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>17.94</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>27783</td>\n",
       "      <td>53.9</td>\n",
       "      <td>38</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   loan_amnt  term_(months)  int_rate  installment  sub_grade  emp_length  \\\n",
       "0       5000             36     10.65       162.87          6        15.0   \n",
       "1       2500             60     15.27        59.83         13         0.5   \n",
       "2       2400             36     15.96        84.33         14        15.0   \n",
       "3      10000             36     13.49       339.31         10        15.0   \n",
       "4       3000             60     12.69        67.79          9         1.0   \n",
       "\n",
       "   home_ownership  annual_inc    dti  open_acc  pub_rec  revol_bal  \\\n",
       "0               4     24000.0  27.65         3        0      13648   \n",
       "1               4     30000.0   1.00         3        0       1687   \n",
       "2               4     12252.0   8.72         2        0       2956   \n",
       "3               4     49200.0  20.00        10        0       5598   \n",
       "4               4     80000.0  17.94        15        0      27783   \n",
       "\n",
       "   revol_util  total_acc  mort_acc  pub_rec_bankruptcies  \n",
       "0        83.7          9       0.0                   0.0  \n",
       "1         9.4          4       0.0                   0.0  \n",
       "2        98.5         10       0.0                   0.0  \n",
       "3        21.0         37       0.0                   0.0  \n",
       "4        53.9         38       0.0                   0.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_numeric.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xg_train, xg_test, xg_ytrain, xg_ytest = sklearn.model_selection.train_test_split(\n",
    "#     X_train_numeric, y_train_numeric, test_size=0.2, random_state=0)\n",
    "\n",
    "# print(xg_train.shape, xg_test.shape, xg_ytrain.shape, xg_ytest.shape)\n",
    "# print(type(xg_train), type(xg_test), type(xg_ytrain), type(xg_ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def artificial_data(x_train, y_train):\n",
    "    X_balanced = []\n",
    "    Y_balanced = []\n",
    "    for i in range(x_train.shape[0]):\n",
    "        curr_df = x_train.iloc[i,:]\n",
    "        d = curr_df.to_dict()\n",
    "        label = y_train.iloc[i]\n",
    "        if label == 1:\n",
    "            for _ in range(4):\n",
    "                X_balanced.append(d)\n",
    "                Y_balanced.append(label)\n",
    "        X_balanced.append(d)\n",
    "        Y_balanced.append(label)\n",
    "    xg_train = pd.DataFrame(X_balanced)\n",
    "    xg_ytrain = pd.Series(Y_balanced)\n",
    "    return (xg_train, xg_ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy Measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auc(m, x_train, x_test, y_train, y_test): \n",
    "    return (metrics.roc_auc_score(y_train,m.predict_proba(x_train)[:,1]),\n",
    "                            metrics.roc_auc_score(y_test,m.predict_proba(x_test)[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Rohan/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:52:36] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"feature_selected\", \"silent\", \"verbose\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:52:37] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Rohan/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:53:12] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"feature_selected\", \"silent\", \"verbose\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:53:12] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Rohan/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:53:53] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"feature_selected\", \"silent\", \"verbose\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:53:53] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Rohan/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:54:29] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"feature_selected\", \"silent\", \"verbose\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:54:29] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Rohan/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:55:06] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"feature_selected\", \"silent\", \"verbose\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:55:06] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Max training score is 0.7987879793911465\n",
      "\n",
      "Average training score is 0.797107131942247\n",
      "\n",
      "Max testing score is 0.6817740152643275\n",
      "\n",
      "Average testing score is 0.6774012345300295\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_folds = 5\n",
    "kf = KFold(n_folds, shuffle = True)\n",
    "training_accuracy_scores = []\n",
    "testing_accuracy_scores = []\n",
    "for train_idx, test_idx in kf.split(X_train_numeric):\n",
    "    kf_Xtrain, xg_kf_Xtest = X_train_numeric.iloc[train_idx], X_train_numeric.iloc[test_idx]\n",
    "    kf_ytrain, xg_kf_ytest = y_train_numeric.iloc[train_idx], y_train_numeric.iloc[test_idx]\n",
    "    xg_kf_Xtrain, xg_kf_ytrain  = artificial_data(kf_Xtrain, kf_ytrain)\n",
    "    model = xgb.XGBClassifier(max_depth=7, min_child_weight=1, learning_rate=0.2, subsample=0.95,\n",
    "                          colsample_bytree=0.95,silent=1, feature_selected=[\"ohe\",\"lin\"],\n",
    "                          objective='binary:logistic', eval_metric='auc', num_boost_round=36)\n",
    "    model.fit(xg_kf_Xtrain,xg_kf_ytrain)\n",
    "    predictions = model.predict_proba(xg_kf_Xtest)[:,1]\n",
    "    scores = auc(model, xg_kf_Xtrain, xg_kf_Xtest, xg_kf_ytrain, xg_kf_ytest)\n",
    "    training_accuracy_scores.append(scores[0])\n",
    "    testing_accuracy_scores.append(scores[1])\n",
    "print(f'Max training score is {max(training_accuracy_scores)}\\n')\n",
    "print(f'Average training score is {np.average(training_accuracy_scores)}\\n')\n",
    "print(f'Max testing score is {max(testing_accuracy_scores)}\\n')\n",
    "print(f'Average testing score is {np.average(testing_accuracy_scores)}\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# model = xgb.XGBClassifier(max_depth=10, min_child_weight=2,  n_estimators=100,\n",
    "#                           n_jobs=-1,learning_rate=0.01, gamma=4)\n",
    "# model.fit(xg_train,xg_ytrain)\n",
    "# predictions1 = model.predict_proba(xg_test)[:,1]\n",
    "# predictions2 = model.predict_proba(xg_test)\n",
    "# print(predictions2)\n",
    "\n",
    "# print(auc(model, xg_train, xg_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search for Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Parameter Tuning\n",
    "# model = xgb.XGBClassifier()\n",
    "# param_dist = {\"max_depth\": [5, 10, 20, 50],\n",
    "#               \"min_child_weight\" : [1, 2, 5, 10],\n",
    "#               \"n_estimators\": [20, 50, 100, 200, 300, 500],\n",
    "#               \"learning_rate\": [0.01, .02, .03, 0.05, .1],\n",
    "#               \"gamma\" : [0,1,4,10],\n",
    "#               \"random_state\" : [0, 20, 40, 100]}\n",
    "# grid_search = GridSearchCV(model, param_grid=param_dist, cv = 3, \n",
    "#                                    verbose=10, n_jobs=-1)\n",
    "# grid_search.fit(xg_train, xg_ytrain)\n",
    "\n",
    "# print(grid_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "752579dbebe7f4dfe7c1aa72eac13e23fc88be2cc1ea7ab14e1f8d69b2d97d12"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
