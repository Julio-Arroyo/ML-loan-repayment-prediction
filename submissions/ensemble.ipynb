{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import category_encoders as ce\n",
    "import sklearn\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "import csv"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "source": [
    "train_data = pd.read_csv('../data/LOANS_TRAIN.csv')\n",
    "test_data = pd.read_csv('../data/LOANS_TEST.csv')\n",
    "\n",
    "id_column = train_data\n",
    "\n",
    "train_data.drop(columns=['id','grade', 'emp_title', 'title'], axis=1, inplace=True)\n",
    "test_data.drop(columns=['id','grade', 'emp_title', 'title'], axis=1, inplace=True)\n",
    "\n",
    "labelencoder = LabelEncoder()\n",
    "# Assigning numerical values and storing in another column\n",
    "train_data['sub_grade'] = labelencoder.fit_transform(train_data['sub_grade'])\n",
    "train_data['home_ownership'] = labelencoder.fit_transform(train_data['home_ownership'])\n",
    "train_data['emp_length'].replace('< 1 year', 0.5, inplace=True)\n",
    "train_data['emp_length'].replace('1 year', 1.0, inplace=True)\n",
    "train_data['emp_length'].replace('2 years', 2.0, inplace=True)\n",
    "train_data['emp_length'].replace('3 years', 3.0, inplace=True)\n",
    "train_data['emp_length'].replace('4 years', 4.0, inplace=True)\n",
    "train_data['emp_length'].replace('5 years', 5.0, inplace=True)\n",
    "train_data['emp_length'].replace('6 years', 6.0, inplace=True)\n",
    "train_data['emp_length'].replace('7 years', 7.0, inplace=True)\n",
    "train_data['emp_length'].replace('8 years', 8.0, inplace=True)\n",
    "train_data['emp_length'].replace('9 years', 9.0, inplace=True)\n",
    "train_data['emp_length'].replace('10 years', 10.0, inplace=True)\n",
    "train_data['emp_length'].replace('10+ years', 15.0, inplace=True)\n",
    "train_data['emp_length'] = train_data['emp_length'].fillna(0)\n",
    "\n",
    "train_data['mort_acc'] = train_data['mort_acc'].fillna(0)\n",
    "# Strip percent(%) from int_rate\n",
    "train_data['int_rate'] = train_data['int_rate'].str.rstrip('%').astype(float)\n",
    "test_data['int_rate'] = test_data['int_rate'].str.rstrip('%').astype(float)\n",
    "\n",
    "#Strip percent(%) from revol_util\n",
    "train_data['revol_util'] = train_data['revol_util'].str.rstrip('%').astype(float)\n",
    "test_data['revol_util'] = test_data['revol_util'].str.rstrip('%').astype(float)\n",
    "\n",
    "X_train = train_data.iloc[:,:-1]\n",
    "y_train = train_data.iloc[:,-1]\n",
    "X_test = test_data.iloc[:,:]\n",
    "\n",
    "X_train_numeric = X_train.select_dtypes(include=np.number)\n",
    "X_test_numeric = X_train.select_dtypes(include=np.number)\n",
    "# y_train_numeric = y_train.select_dtypes(include=np.number)\n",
    "y_train_numeric = y_train.copy(deep=False)\n",
    "y_train_numeric.replace('Fully Paid', 0.0, inplace=True)\n",
    "y_train_numeric.replace('Charged Off', 1.0, inplace=True)\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "source": [
    "# X_val_numeric = X_train_numeric.sample(frac=0.2)\n",
    "# val_indices = X_val_numeric.index\n",
    "# X_train_numeric = X_train_numeric.drop(val_indices)\n",
    "# train_indices = X_train_numeric.index\n",
    "# Y_val = y_train_numeric.drop(train_indices)\n",
    "# y_train = y_train_numeric.drop(val_indices)\n",
    "\n",
    "# print(train_indices)\n",
    "# print(val_indices)\n",
    "\n",
    "train_X, val_X, train_y, val_y = sklearn.model_selection.train_test_split(X_train_numeric, y_train_numeric, test_size=0.2, random_state=0)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "        loan_amnt  term_(months)  int_rate  installment  sub_grade  \\\n",
      "89545        9800             36     19.52       361.82         18   \n",
      "190443      16000             60     18.49       410.58         16   \n",
      "57541       13275             36      6.62       407.60          1   \n",
      "124679       3000             36     16.29       105.91         13   \n",
      "119027       5000             36     12.35       166.91          8   \n",
      "...           ...            ...       ...          ...        ...   \n",
      "152315      24175             36     12.12       804.35          7   \n",
      "176963      35000             36     15.80      1227.05         12   \n",
      "117952       2400             36     14.33        82.42         11   \n",
      "173685       7750             36     12.12       257.86          7   \n",
      "43567       12175             36     10.99       398.54          6   \n",
      "\n",
      "        emp_length  home_ownership  annual_inc    dti  open_acc  pub_rec  \\\n",
      "89545          5.0               4     43372.8  26.28        14        0   \n",
      "190443        15.0               4     43956.0  32.43         6        0   \n",
      "57541         15.0               4    100000.0  27.25         7        0   \n",
      "124679        15.0               4     27000.0  28.84         9        1   \n",
      "119027        15.0               0    150000.0   6.75         7        0   \n",
      "...            ...             ...         ...    ...       ...      ...   \n",
      "152315         0.0               0    120000.0   9.09        16        0   \n",
      "176963        15.0               4     83000.0  24.56        11        0   \n",
      "117952        15.0               0    108090.0  29.73        15        0   \n",
      "173685         0.0               0     34000.0  17.36         7        0   \n",
      "43567         15.0               0     78704.0  28.89        16        0   \n",
      "\n",
      "        revol_bal  revol_util  total_acc  mort_acc  pub_rec_bankruptcies  \n",
      "89545        3768        85.6         29       0.0                   0.0  \n",
      "190443       5106        61.5         36       0.0                   0.0  \n",
      "57541       13282        56.0         34       5.0                   0.0  \n",
      "124679      12077        48.3         13       0.0                   1.0  \n",
      "119027       6704        76.2         21       4.0                   0.0  \n",
      "...           ...         ...        ...       ...                   ...  \n",
      "152315      33873        79.9         38       6.0                   0.0  \n",
      "176963      16084        61.5         47       2.0                   0.0  \n",
      "117952      35985        78.1         31       2.0                   0.0  \n",
      "173685       9204        34.3         17       3.0                   0.0  \n",
      "43567       39302        58.9         44       6.0                   0.0  \n",
      "\n",
      "[157800 rows x 16 columns]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "source": [
    "model = xgb.XGBClassifier(max_depth=6, min_child_weight=1,  n_estimators=30,\n",
    "                            n_jobs=-1,learning_rate=0.2, alpha=10)\n",
    "model.fit(train_X, train_y)\n",
    "xgb_predictions = model.predict_proba(val_X)[:,1]\n",
    "print('AUC XGB')\n",
    "print(sklearn.metrics.roc_auc_score(val_y, xgb_predictions))\n",
    "print(sklearn.metrics.roc_auc_score(train_y, model.predict_proba(train_X)[:,1]))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[23:24:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "AUC XGB\n",
      "0.6848892678484035\n",
      "0.7105160979433875\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "END OF XGBOOST TRAINING, START OF CNN"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from torch.utils.data import DataLoader, random_split\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "train_data = pd.read_csv('./data/LOANS_TRAIN.csv')\n",
    "test_data = pd.read_csv('./data/LOANS_TEST.csv')\n",
    "\n",
    "id_column = test_data['id']\n",
    "\n",
    "train_data.drop(columns=['id','grade', 'emp_title', 'title', 'earliest_cr_line', 'issue_d', 'zip_code'], axis=1, inplace=True)\n",
    "test_data.drop(columns=['id','grade', 'emp_title', 'title', 'earliest_cr_line', 'issue_d', 'zip_code'], axis=1, inplace=True)\n",
    "\n",
    "# we want to ultimately use this data, but its nominal multi-categorical nature requires further preprocessing\n",
    "# prolly with OneHotEncoder\n",
    "    # Deal with nominal, multi-categorical data\n",
    "    # Goal: convert home_ownership (RENT, OWN, MORTGAGE, OTHER) to a 4D vector.\n",
    "        # if MORTGAGE ==> [0,0,1,0]\n",
    "# print(len(train_data['zip_code'].unique()))\n",
    "# print(train_data['zip_code'].unique())\n",
    "ce_OHE = ce.OneHotEncoder(cols=['addr_state', 'home_ownership', 'purpose'])\n",
    "print('BEFORE')\n",
    "print(train_data.shape)\n",
    "train_data = ce_OHE.fit_transform(train_data)\n",
    "print('AFTER')\n",
    "print(train_data.shape)\n",
    "test_data = ce_OHE.fit_transform(test_data)\n",
    "# NOTE: 'purpose' only has 14 categories, probably good things to learn from\n",
    "\n",
    "# there are no joint applications in training, so model won't be able to learn it. Better to drop it\n",
    "train_data.drop(columns=['application_type', 'purpose_14'], axis=1, inplace=True)\n",
    "test_data.drop(columns=['application_type'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "labelencoder = LabelEncoder()\n",
    "labelencoder2 = LabelEncoder()\n",
    "# Assigning numerical values and storing in another column\n",
    "train_data['sub_grade'] = labelencoder.fit_transform(train_data['sub_grade'])\n",
    "train_data['emp_length'].replace('< 1 year', 0, inplace=True)\n",
    "train_data['emp_length'].replace('1 year', 1.0, inplace=True)\n",
    "train_data['emp_length'].replace('2 years', 2.0, inplace=True)\n",
    "train_data['emp_length'].replace('3 years', 3.0, inplace=True)\n",
    "train_data['emp_length'].replace('4 years', 4.0, inplace=True)\n",
    "train_data['emp_length'].replace('5 years', 5.0, inplace=True)\n",
    "train_data['emp_length'].replace('6 years', 6.0, inplace=True)\n",
    "train_data['emp_length'].replace('7 years', 7.0, inplace=True)\n",
    "train_data['emp_length'].replace('8 years', 8.0, inplace=True)\n",
    "train_data['emp_length'].replace('9 years', 9.0, inplace=True)\n",
    "train_data['emp_length'].replace('10 years', 10.0, inplace=True)\n",
    "train_data['emp_length'].replace('10+ years', 15.0, inplace=True)\n",
    "train_data['emp_length'] = train_data['emp_length'].fillna(0)\n",
    "train_data['pub_rec_bankruptcies'] = train_data['pub_rec_bankruptcies'].fillna(0)\n",
    "train_data['verification_status'].replace('Verified', 1, inplace=True)\n",
    "train_data['verification_status'].replace('Source Verified', 1, inplace=True)\n",
    "train_data['verification_status'].replace('Not Verified', 0, inplace=True)\n",
    "train_data['initial_list_status'].replace('w', 1, inplace=True)\n",
    "train_data['initial_list_status'].replace('f', 0, inplace=True)\n",
    "\n",
    "test_data['sub_grade'] = labelencoder2.fit_transform(test_data['sub_grade'])\n",
    "test_data['emp_length'].replace('< 1 year', 0, inplace=True)\n",
    "test_data['emp_length'].replace('1 year', 1.0, inplace=True)\n",
    "test_data['emp_length'].replace('2 years', 2.0, inplace=True)\n",
    "test_data['emp_length'].replace('3 years', 3.0, inplace=True)\n",
    "test_data['emp_length'].replace('4 years', 4.0, inplace=True)\n",
    "test_data['emp_length'].replace('5 years', 5.0, inplace=True)\n",
    "test_data['emp_length'].replace('6 years', 6.0, inplace=True)\n",
    "test_data['emp_length'].replace('7 years', 7.0, inplace=True)\n",
    "test_data['emp_length'].replace('8 years', 8.0, inplace=True)\n",
    "test_data['emp_length'].replace('9 years', 9.0, inplace=True)\n",
    "test_data['emp_length'].replace('10 years', 10.0, inplace=True)\n",
    "test_data['emp_length'].replace('10+ years', 15.0, inplace=True)\n",
    "test_data['emp_length'] = test_data['emp_length'].fillna(0)\n",
    "test_data['pub_rec_bankruptcies'] = test_data['pub_rec_bankruptcies'].fillna(0)\n",
    "test_data['verification_status'].replace('Verified', 1, inplace=True)\n",
    "# technically encoding two categories into one... might want to change\n",
    "test_data['verification_status'].replace('Verified', 1, inplace=True)\n",
    "test_data['verification_status'].replace('Source Verified', 1, inplace=True)\n",
    "test_data['verification_status'].replace('Not Verified', 0, inplace=True)\n",
    "test_data['initial_list_status'].replace('w', 1, inplace=True)\n",
    "test_data['initial_list_status'].replace('f', 0, inplace=True)\n",
    "\n",
    "train_data['mort_acc'] = train_data['mort_acc'].fillna(0)\n",
    "\n",
    "test_data['mort_acc'] = test_data['mort_acc'].fillna(0)\n",
    "# Strip percent(%) from int_rate\n",
    "train_data['int_rate'] = train_data['int_rate'].str.rstrip('%').astype(float)\n",
    "test_data['int_rate'] = test_data['int_rate'].str.rstrip('%').astype(float)\n",
    "\n",
    "#Strip percent(%) from revol_util\n",
    "train_data['revol_util'] = train_data['revol_util'].str.rstrip('%').astype(float)\n",
    "test_data['revol_util'] = test_data['revol_util'].str.rstrip('%').astype(float)\n",
    "train_data['revol_util'] = train_data['revol_util'].fillna(0)\n",
    "test_data['revol_util'] = test_data['revol_util'].fillna(0)\n",
    "\n",
    "X_train = train_data.iloc[:,:-1]\n",
    "y_train = train_data.iloc[:,-1]\n",
    "X_test = test_data.iloc[:,:]\n",
    "X_train_numeric = X_train.select_dtypes(include=np.number)\n",
    "X_test_numeric = X_test.select_dtypes(include=np.number)\n",
    "# y_train_numeric = y_train.select_dtypes(include=np.number)\n",
    "y_train_numeric = y_train.copy(deep=False)\n",
    "y_train_numeric.replace('Fully Paid', 0.0, inplace=True)\n",
    "y_train_numeric.replace('Charged Off', 1.0, inplace=True)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X_val_numeric = X_train_numeric.drop(train_indices)\n",
    "Y_val = y_train.drop(train_indices)\n",
    "X_train_numeric = X_train_numeric.drop(val_indices)\n",
    "y_train = y_train.drop(val_indices)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for col in X_train_numeric.columns:\n",
    "    if X_train_numeric[col].isnull().values.any() > 0:\n",
    "        print(col)\n",
    "    x_min = X_train_numeric[col].min()\n",
    "    x_max = X_train_numeric[col].max()\n",
    "    X_train_numeric[col] = (X_train_numeric[col] - x_min) / (x_max - x_min)\n",
    "    # also need to normalize test data, but must use training data\n",
    "    X_test_numeric[col] = (X_test_numeric[col] - x_min) / (x_max - x_min)\n",
    "    X_test_numeric[col].mask(X_test_numeric[col] < 0, 0, inplace=True)\n",
    "    X_test_numeric[col].mask(X_test_numeric[col] > 1, 1, inplace=True)\n",
    "    # TODO: DETERMINE WHAT TO DO IN THESE CASES!!!\n",
    "    if X_test_numeric[col].min() < 0:\n",
    "        print(f\"min is less than zero in test data in column {col}\")\n",
    "        print(X_test_numeric[col].min())\n",
    "    if X_test_numeric[col].max() > 1:\n",
    "        print(f\"max is more than one in test data in column {col}\")\n",
    "        print(X_test_numeric[col].max())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Conv2d(in_channels=1, out_channels=64, kernel_size=(1, 3), stride=1, padding=0),\n",
    "    nn.BatchNorm2d(64),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.MaxPool2d(kernel_size=(1, 2), stride=1),\n",
    "    nn.Conv2d(in_channels=64, out_channels=64, kernel_size=(1, 3), stride=1, padding=0),\n",
    "    nn.BatchNorm2d(64),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.MaxPool2d(kernel_size=(1, 2), stride=1),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(5056, 512),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(p=0.25),\n",
    "    nn.Linear(512, 1),\n",
    "    nn.Sigmoid()\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# our model has some # of parameters:\n",
    "count = 0\n",
    "for p in model.parameters():\n",
    "    n_params = np.prod(list(p.data.shape)).item()\n",
    "    count += n_params\n",
    "print(f'total params: {count}')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Custom Dataset\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, X, Y):\n",
    "        \"\"\"\n",
    "        X: a dataframe with rows as training examples and columns features\n",
    "        Y: a pandas series with labels\"\"\"\n",
    "        self.x_train=torch.tensor(X.values, dtype=torch.float32)\n",
    "        self.y_train=torch.tensor(Y.values, dtype=torch.float32)\n",
    "        self.x_train = torch.reshape(self.x_train, (self.x_train.shape[0], 1, 1, self.x_train.shape[1],))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y_train)\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        return (self.x_train[idx], self.y_train[idx])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "BATCH_SIZE = 512\n",
    "\n",
    "ds_train = CustomDataset(X_train_numeric, y_train_numeric)\n",
    "ds_val = CustomDataset(X_val_numeric, Y_val)\n",
    "train_loader = DataLoader(ds_train, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_eval_loader = DataLoader(ds_val, batch_size=len_val, shuffle=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "n_epochs = 10  # paper used 100 originally\n",
    "lr = 0.001\n",
    "\n",
    "train_loss_hist = np.zeros([n_epochs, 1])\n",
    "val_loss_hist = np.zeros([n_epochs, 1])\n",
    "for epoch in range(n_epochs):\n",
    "    print(f'EPOCH {epoch}')\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for i, data in enumerate(train_loader):\n",
    "        features, labels = data\n",
    "        # print(type(features))\n",
    "        # print(f\"PESKY BASTARDS: {features.isnan().sum()}\")\n",
    "        optimizer.zero_grad()\n",
    "        # forward pass\n",
    "        output = model(features)\n",
    "        output = torch.reshape(output, (output.shape[0], ))\n",
    "        if output.isnan().sum() > 0:\n",
    "            print(f\"RIP{output.isnan().sum()}\")\n",
    "        output = torch.nan_to_num(output)\n",
    "        # calculate loss\n",
    "        loss = criterion(output, labels)\n",
    "        # backward pass\n",
    "        loss.backward()\n",
    "        # update\n",
    "        optimizer.step()\n",
    "        # track training loss\n",
    "        train_loss_hist[epoch] += loss.item()\n",
    "    train_loss_hist[epoch] /= len(train_loader)\n",
    "    print(f\"\\ttraining loss: {train_loss_hist[epoch]}\")\n",
    "\n",
    "    # validate\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        output = None\n",
    "        labels = None\n",
    "        for i, data in enumerate(val_eval_loader):\n",
    "            features, labels = data\n",
    "            output = model(features)\n",
    "            output = torch.reshape(output, (output.shape[0], ))\n",
    "            output = torch.nan_to_num(output)\n",
    "            loss = criterion(output, labels)\n",
    "            val_loss_hist[epoch] += loss.item()\n",
    "        preds = output.cpu().detach().numpy()\n",
    "        ground_truths = labels.cpu().detach().numpy()\n",
    "        print(f'\\tAUC: {sklearn.metrics.roc_auc_score(ground_truths, preds)}')\n",
    "        val_loss_hist[epoch] /= len(val_eval_loader)\n",
    "        print(f\"\\tvalidation loss: {val_loss_hist[epoch]}\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# validate\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    output = None\n",
    "    labels = None\n",
    "    for i, data in enumerate(val_eval_loader):\n",
    "        features, labels = data\n",
    "        output = model(features)\n",
    "        output = torch.reshape(output, (output.shape[0], ))\n",
    "        output = torch.nan_to_num(output)\n",
    "        loss = criterion(output, labels)\n",
    "        val_loss_hist[epoch] += loss.item()\n",
    "    preds = output.cpu().detach().numpy()\n",
    "    ground_truths = labels.cpu().detach().numpy()\n",
    "    print(f'\\tAUC: {sklearn.metrics.roc_auc_score(ground_truths, preds)}')\n",
    "    val_loss_hist[epoch] /= len(val_eval_loader)\n",
    "    print(f\"\\tvalidation loss: {val_loss_hist[epoch]}\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# TODO: create points of the form (1, xgb pred, cnn pred) and plot them by color according to their ground truth label\n",
    "# see if they are linearly separable"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# # Test Dataset\n",
    "\n",
    "# class TestDataset(Dataset):\n",
    "#     def __init__(self, X):\n",
    "#         \"\"\"\n",
    "#         X: a dataframe with rows as training examples and columns features\n",
    "#         Y: a pandas series with labels\"\"\"\n",
    "#         self.x_train=torch.tensor(X.values, dtype=torch.float32)\n",
    "#         self.x_train = torch.reshape(self.x_train, (self.x_train.shape[0], 1, 1, self.x_train.shape[1],))\n",
    "\n",
    "#     def __len__(self):\n",
    "#         print(f'GETTING LENGTH {self.x_train.shape[0]}')\n",
    "#         return self.x_train.shape[0]\n",
    "\n",
    "#     def __getitem__(self,idx):\n",
    "#         return self.x_train[idx]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# ds_test = TestDataset(X_test_numeric)\n",
    "\n",
    "# test_loader = torch.utils.data.Dataloader(ds_test, batch_size=1, shuffle=True)\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     model.eval()\n",
    "#     cnn_predictions = []\n",
    "#     for i, data in enumerate(test_loader):\n",
    "#         features = data\n",
    "#         output = model(features)\n",
    "#         output = torch.reshape(output, (output.shape[0], ))\n",
    "#         if output.isnan().sum() > 0:\n",
    "#             print(f\"RIP{output.isnan().sum()}\")\n",
    "#         output = torch.nan_to_num(output)\n",
    "#         print(f'PREDICTION: {output.item()}')\n",
    "#         cnn_predictions.append(output.item())\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "ensemble_features = []\n",
    "\n",
    "assert len(cnn_predictions) == len(xgb_predictions)\n",
    "\n",
    "for i in range(len(cnn_predictions)):\n",
    "    \n"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "752579dbebe7f4dfe7c1aa72eac13e23fc88be2cc1ea7ab14e1f8d69b2d97d12"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}