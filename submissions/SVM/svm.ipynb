{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "# import matplotlib.pyplot as plt\n",
    "# import category_encoders as ce\n",
    "import sklearn.metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import random\n",
    "from sklearn import svm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('../data/LOANS_TRAIN.csv')\n",
    "test_data = pd.read_csv('../data/LOANS_TEST.csv')\n",
    "\n",
    "train_data = train_data.drop(columns=['id',\n",
    "                                      'addr_state',\n",
    "                                      'application_type',\n",
    "                                      'earliest_cr_line',\n",
    "                                      'emp_title',\n",
    "                                      'home_ownership',\n",
    "                                      'initial_list_status',\n",
    "                                      'issue_d',\n",
    "                                      'purpose',\n",
    "                                      'sub_grade',\n",
    "                                      'title',\n",
    "                                      'verification_status',\n",
    "                                      'zip_code',\n",
    "                                      'mort_acc',\n",
    "                                      'emp_length',\n",
    "                                      'revol_util'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "grade_2_index = {\"A\": 0,\n",
    "                 \"B\": 1,\n",
    "                 \"C\": 2,\n",
    "                 \"D\": 3,\n",
    "                 \"E\": 4, \n",
    "                 \"F\": 5,\n",
    "                 \"G\": 6}\n",
    "\n",
    "# Get features: income, dti\n",
    "X = []\n",
    "Y = []\n",
    "for index, row in train_data.iterrows():\n",
    "    idx = grade_2_index[row['grade']]\n",
    "    feature = [0 for _ in range(7)]\n",
    "    feature[idx] = 1\n",
    "    X.append(feature)\n",
    "\n",
    "    label = row['loan_status']\n",
    "    if label == 'Fully Paid':\n",
    "        Y.append(0)\n",
    "    else:\n",
    "        Y.append(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NEURAL NETWORKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        self.X = features\n",
    "        self.Y = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the total number of samples'\n",
    "        return len(self.Y)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        'Generates one sample of data'\n",
    "        # Select sample\n",
    "        # print(f\"SHAPE {self.X.shape}, {self.Y.shape}\")\n",
    "        # print(f\"({self.X[index]}, {self.Y[index]})\")\n",
    "        y = torch.reshape(self.Y[index], (1,))\n",
    "        return self.X[index], y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "287922\n"
     ]
    }
   ],
   "source": [
    "# fix class imbalance\n",
    "X_balanced = []\n",
    "Y_balanced = []\n",
    "for k in range(len(X)):\n",
    "    if Y[k] == 1:\n",
    "        for _ in range(3):\n",
    "            X_balanced.append(X[k])\n",
    "            Y_balanced.append(Y[k])\n",
    "    X_balanced.append(X[k])\n",
    "    Y_balanced.append(Y[k])\n",
    "\n",
    "print(len(X_balanced))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "DLmodel = nn.Sequential(\n",
    "    nn.Linear(7, 20),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(20, 10),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(10, 1),\n",
    "    nn.Sigmoid()\n",
    ")\n",
    "optimizer = torch.optim.Adam(DLmodel.parameters(), lr=1e-3)\n",
    "loss_fn = nn.BCELoss()\n",
    "\n",
    "X_tensor = torch.FloatTensor(X_balanced)\n",
    "Y_tensor = torch.FloatTensor(Y_balanced)\n",
    "dataset = CustomDataset(X_tensor, Y_tensor)\n",
    "train_loader = torch.utils.data.DataLoader(dataset, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "DLmodel.train()\n",
    "\n",
    "for epoch in range(5):\n",
    "    correct = 0\n",
    "    for batch_idx, (data, label) in enumerate(train_loader):\n",
    "        # Erase accumulated gradients\n",
    "        optimizer.zero_grad()\n",
    "        # Forward pass\n",
    "        output = DLmodel(data)\n",
    "        # output = torch.reshape(output, (1,))\n",
    "        # print('FUCS')\n",
    "        # print(output)\n",
    "        # print(type(output))\n",
    "        # print(type(label))\n",
    "        # print(label)\n",
    "        # Calculate loss\n",
    "        # output_tensor = torch.FloatTensor(output)\n",
    "        # label_tensor = torch.reshape(output, (1, 1))\n",
    "        # print(f'SHAPES {output.shape}, {label_tensor.shape}')\n",
    "        # print(f'tensors {output}, {label_tensor}')\n",
    "        loss = nn.functional.binary_cross_entropy_with_logits(output, label)\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # Weight update\n",
    "        optimizer.step()\n",
    "\n",
    "        # to calculate accuracy\n",
    "        pred = output.argmax(dim=1, keepdim=True)  # Get the index of the max class score\n",
    "        correct += pred.eq(label.view_as(pred)).sum().item()\n",
    "\n",
    "    # Track loss each epoch\n",
    "    print('Train Epoch: %d  Loss: %.4f. Training Accuracy: (%.4f)' % (epoch + 1,  loss.item(), 100*correct/len(train_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE\n",
      "tensor([2.1910e-13], grad_fn=<SigmoidBackward>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6343040086159206"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = DLmodel(X_tensor)\n",
    "# print(pred)\n",
    "# prob_preds = []\n",
    "# for j in range(len(pred)):\n",
    "#     prob_preds.append(pred[j][1])\n",
    "print(\"SCORE\")\n",
    "print(DLmodel(torch.FloatTensor([1,0,0,0,0,0,0])))\n",
    "sklearn.metrics.roc_auc_score(Y_balanced, pred.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = {\"id\": [], \"loan_status\": []}\n",
    "for index, row in test_data.iterrows():\n",
    "    credit_score = row[\"grade\"]\n",
    "    idx = grade_2_index[credit_score]\n",
    "    feature = [0 for _ in range(7)]\n",
    "    feature[idx] = 1\n",
    "    feature = torch.FloatTensor(feature)\n",
    "    # print(feature)\n",
    "    # print(type(feature))\n",
    "    prediction = DLmodel(feature).item()\n",
    "    # print(prediction)\n",
    "    predictions[\"id\"].append(row['id'])\n",
    "    predictions[\"loan_status\"].append(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/x2/kz7ljbl93cs7d61qrkfn3js00000gn/T/ipykernel_40427/3607207663.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpredictions_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mpredictions_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"neural_net_balanced_predictions\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "predictions_df = pd.DataFrame(data=predictions)\n",
    "predictions_df.to_csv(\"neural_net_balanced_predictions\", index=False)\n",
    "assert False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE\n",
      "0.08122640241594924\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6545479517428292"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression(C=0.001)\n",
    "model.fit(X, Y)\n",
    "pred = model.predict_proba(X)\n",
    "prob_preds = []\n",
    "for j in range(len(pred)):\n",
    "    prob_preds.append(pred[j][1])\n",
    "print(\"SCORE\")\n",
    "print(model.predict_proba([[1,0,0,0,0,0,0]])[0][1])\n",
    "sklearn.metrics.roc_auc_score(Y, prob_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = {\"id\": [], \"loan_status\": []}\n",
    "for index, row in test_data.iterrows():\n",
    "    credit_score = row[\"grade\"]\n",
    "    idx = grade_2_index[credit_score]\n",
    "    feature = [0 for _ in range(7)]\n",
    "    feature[idx] = 1\n",
    "    prediction = model.predict_proba([feature])[0][1]\n",
    "    predictions[\"id\"].append(row['id'])\n",
    "    predictions[\"loan_status\"].append(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df = pd.DataFrame(data=predictions)\n",
    "predictions_df.to_csv(\"LLLLL_predictions\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get features: income, dti\n",
    "# predictions = []\n",
    "# ground_truths = []\n",
    "# indicator = True\n",
    "# X = []\n",
    "# NAN_count = 0\n",
    "# for index, row in train_X.iterrows():\n",
    "#     nan_indices = pd.Series.tolist(row.isnull())\n",
    "\n",
    "#     features =pd.Series.to_list(row)\n",
    "#     for i in range(len(nan_indices)):\n",
    "#         if nan_indices[i] == True:\n",
    "#             features[i] = 0\n",
    "#             NAN_count += 1\n",
    "    \n",
    "#     # convert percent to decimal\n",
    "#     features[2] = float(features[2].strip('%'))/100\n",
    "\n",
    "#     X.append(features)\n",
    "# print(f'FOUND NANCOUTN {NAN_count}')\n",
    "# print(f\"entries {train_X.shape}\")\n",
    "# Y = []\n",
    "# for label in train_y.values:\n",
    "#     if label == 'Fully Paid':\n",
    "#         Y.append(0)\n",
    "#     else:\n",
    "#         Y.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get features: income, dti\n",
    "# X = []\n",
    "# for index, row in train_X.iterrows():\n",
    "#     features = [row['annual_inc'], row['dti']]\n",
    "#     X.append(features)\n",
    "\n",
    "# Y = []\n",
    "# for label in train_y.values:\n",
    "#     if label == 'Fully Paid':\n",
    "#         Y.append(0)\n",
    "#     else:\n",
    "#         Y.append(1)\n",
    "# print(np.unique(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = svm.SVC(kernel='rbf') # consider parameter probability=True\n",
    "\n",
    "# count = 0\n",
    "# for j in range(len(Y)):\n",
    "#     if Y[j] == 0:\n",
    "#         count += 1\n",
    "# print(f'CONT {count}')\n",
    "# X_sample = []\n",
    "# Y_sample = []\n",
    "# budget0 = 17000\n",
    "# budget1 = 15000\n",
    "# for i in range(len(Y), -1, -1):\n",
    "#     if Y[j] == 0:\n",
    "#         budget0 -= 1\n",
    "#     else:\n",
    "#         budget1 -= 1\n",
    "#     X_sample.append(X[j])\n",
    "#     Y_sample.append(Y[j])\n",
    "#     if budget0 == 0 or budget1 == 0:\n",
    "#         break\n",
    "\n",
    "# print(f'YSAMPLE UNIQUE {np.unique(Y_sample)}')\n",
    "# print(len(X_sample))\n",
    "# model.fit(X_sample, Y_sample)\n",
    "# in_sample_preds = model.predict(X_sample)\n",
    "# print(np.unique(in_sample_preds))\n",
    "# # print(in_sample_preds)\n",
    "\n",
    "# print(\"SCORE\")\n",
    "# sklearn.metrics.roc_auc_score(Y_sample, in_sample_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = svm.SVC(kernel='linear') # consider parameter probability=True\n",
    "# Y = train_y.values.tolist()\n",
    "# model.fit(X, Y)\n",
    "# in_sample_preds = model.predict(X)\n",
    "\n",
    "# sklearn.metrics.roc_auc_score(Y, in_sample_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = svm.SVC(kernel='rbf') # consider parameter probability=True\n",
    "\n",
    "# X_sample = []\n",
    "# Y_sample = []\n",
    "# for j in range(len(X)):\n",
    "#     p = random.random()\n",
    "#     if p <= 0.4:\n",
    "#         X_sample.append(X[j])\n",
    "#         Y_sample.append(Y[j])\n",
    "# print(f'YSAMPLE UNIQUE {np.unique(Y_sample)}')\n",
    "# print(len(X_sample))\n",
    "# model.fit(X_sample, Y_sample)\n",
    "# in_sample_preds = model.predict(X_sample)\n",
    "# print(np.unique(in_sample_preds))\n",
    "# # print(in_sample_preds)\n",
    "\n",
    "# print(\"SCORE\")\n",
    "# sklearn.metrics.roc_auc_score(Y_sample, in_sample_preds)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4b5295d72cc8c3d140bbb6686d5919ce0ad0a523816efde1e1cd082b7d39dbc7"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
